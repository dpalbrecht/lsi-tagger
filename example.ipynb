{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6845d714-1fe0-43b0-8b7d-9ab583b3d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from collections import Counter\n",
    "sys.path.append(\"c:/users/david/desktop/sandbox/lsi-tagger\")\n",
    "from model.tag_extractor import TagExtractor\n",
    "from model.text_cleaner import TextCleaner\n",
    "import itertools\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76b076de-bf48-4685-b0c3-34ca8f9fc35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105126, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>prod_name</th>\n",
       "      <th>product_type_no</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>graphical_appearance_no</th>\n",
       "      <th>graphical_appearance_name</th>\n",
       "      <th>colour_group_code</th>\n",
       "      <th>colour_group_name</th>\n",
       "      <th>...</th>\n",
       "      <th>department_name</th>\n",
       "      <th>index_code</th>\n",
       "      <th>index_name</th>\n",
       "      <th>index_group_no</th>\n",
       "      <th>index_group_name</th>\n",
       "      <th>section_no</th>\n",
       "      <th>section_name</th>\n",
       "      <th>garment_group_no</th>\n",
       "      <th>garment_group_name</th>\n",
       "      <th>detail_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108775015</td>\n",
       "      <td>108775</td>\n",
       "      <td>Strap top</td>\n",
       "      <td>253</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>9</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>A</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>16</td>\n",
       "      <td>Womens Everyday Basics</td>\n",
       "      <td>1002</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108775044</td>\n",
       "      <td>108775</td>\n",
       "      <td>Strap top</td>\n",
       "      <td>253</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>10</td>\n",
       "      <td>White</td>\n",
       "      <td>...</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>A</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>16</td>\n",
       "      <td>Womens Everyday Basics</td>\n",
       "      <td>1002</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  product_code  prod_name  product_type_no product_type_name  \\\n",
       "0   108775015        108775  Strap top              253          Vest top   \n",
       "1   108775044        108775  Strap top              253          Vest top   \n",
       "\n",
       "   product_group_name  graphical_appearance_no graphical_appearance_name  \\\n",
       "0  Garment Upper body                  1010016                     Solid   \n",
       "1  Garment Upper body                  1010016                     Solid   \n",
       "\n",
       "   colour_group_code colour_group_name  ...  department_name index_code  \\\n",
       "0                  9             Black  ...     Jersey Basic          A   \n",
       "1                 10             White  ...     Jersey Basic          A   \n",
       "\n",
       "   index_name index_group_no  index_group_name section_no  \\\n",
       "0  Ladieswear              1        Ladieswear         16   \n",
       "1  Ladieswear              1        Ladieswear         16   \n",
       "\n",
       "             section_name garment_group_no  garment_group_name  \\\n",
       "0  Womens Everyday Basics             1002        Jersey Basic   \n",
       "1  Womens Everyday Basics             1002        Jersey Basic   \n",
       "\n",
       "                               detail_desc  \n",
       "0  Jersey top with narrow shoulder straps.  \n",
       "1  Jersey top with narrow shoulder straps.  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/h&m_kaggle_products.csv')\n",
    "df = df[~df.isnull().any(axis=1)]\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567abae3-35f4-40ea-bbaf-67508e331fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 43404/43404 [00:04<00:00, 10115.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43404"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = df['detail_desc'].drop_duplicates().values\n",
    "cleaned_documents = TextCleaner(word_count_min=2, word_length_min=2).clean_documents(documents)\n",
    "len(cleaned_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1556f58f-3292-47c6-97ba-c13daf06e864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\AppData\\Local\\Temp\\ipykernel_15636\\2820098043.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  cleaned_documents = np.array(cleaned_documents)[doc_keep_inds].tolist()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(43404, 43404)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove empty documents\n",
    "doc_keep_inds = np.array([n for n,doc in enumerate(cleaned_documents) if len(doc)>0])\n",
    "cleaned_documents = np.array(cleaned_documents)[doc_keep_inds].tolist()\n",
    "documents = np.array(documents)[doc_keep_inds].tolist()\n",
    "\n",
    "len(documents), len(cleaned_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eef35d04-1d2c-40ea-8412-93d07003c2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2003"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSI (https://radimrehurek.com/gensim/auto_examples/core/run_topics_and_transformations.html)\n",
    "  # https://radimrehurek.com/gensim/models/lsimodel.html\n",
    "dictionary = corpora.Dictionary(cleaned_documents)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in cleaned_documents]\n",
    "\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95eb0b08-a615-475c-81f4-3094cb7d5c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "lsi_model = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=200)\n",
    "corpus_lsi = lsi_model[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "420df802-8595-4278-8d99-5cdd5d0ed6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.179*\"long\" + 0.178*\"sleeves\" + 0.167*\"soft\" + 0.165*\"cuffs\" + 0.165*\"short\" + 0.163*\"hem\" + 0.161*\"pockets\" + 0.158*\"cotton\" + 0.152*\"jersey\" + 0.148*\"waist\"'),\n",
       " (1,\n",
       "  '-0.233*\"pockets\" + 0.232*\"knit\" + 0.223*\"ribbing\" + 0.211*\"jumper\" + -0.207*\"fly\" + 0.198*\"neckline\" + 0.183*\"long\" + -0.174*\"legs\" + 0.174*\"hem\" + 0.164*\"cuffs\"'),\n",
       " (2,\n",
       "  '0.234*\"dress\" + 0.206*\"seam\" + -0.204*\"ribbing\" + 0.194*\"neck\" + -0.189*\"pockets\" + 0.179*\"short\" + -0.178*\"sweatshirt\" + 0.165*\"skirt\" + 0.151*\"unlined\" + 0.149*\"weave\"'),\n",
       " (3,\n",
       "  '-0.331*\"imitation\" + -0.323*\"leather\" + -0.289*\"insoles\" + -0.288*\"soles\" + -0.258*\"linings\" + -0.237*\"cm\" + -0.220*\"rubber\" + -0.196*\"loop\" + -0.155*\"heel\" + -0.141*\"lacing\"'),\n",
       " (4,\n",
       "  '0.268*\"jersey\" + -0.267*\"collar\" + -0.223*\"buttons\" + 0.203*\"elasticated\" + -0.193*\"buttoned\" + -0.183*\"chest\" + -0.183*\"jacket\" + -0.162*\"flap\" + 0.160*\"soft\" + -0.155*\"rounded\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi_model.print_topics(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e610fd64-d13c-4156-9364-ab8c7c988854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsi_corpus2vec(lsi_corpus_vec):\n",
    "    vec = np.zeros(200)\n",
    "    for ind, value in lsi_corpus_vec:\n",
    "        vec[ind] = value\n",
    "    return vec\n",
    "\n",
    "lsi_vecs = np.array([lsi_corpus2vec(cl) for cl in corpus_lsi])\n",
    "lsi_vecs_normed = lsi_vecs/np.linalg.norm(lsi_vecs, axis=1)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b58e5f3-27e0-4e98-ac0f-3921c5dcb3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_topic_matrix = lsi_model.get_topics()\n",
    "\n",
    "def extract_tags(input_ind, candidate_ind, n_tags=5):\n",
    "\n",
    "    # Get shared words using the sparse TF-IDF corpus\n",
    "    shared_word_ids = np.array(list(set(np.array(corpus_tfidf[input_ind])[:,0]) \\\n",
    "                                  & set(np.array(corpus_tfidf[candidate_ind])[:,0]))).astype(int)\n",
    "\n",
    "    # Get word-topic vectors for those shared words\n",
    "    shared_word_topics = lsi_topic_matrix.T[shared_word_ids]\n",
    "\n",
    "    # Sum those word-topic vectors weighed by each document's topic loadings\n",
    "    shared_lsi_word_loadings = np.sum((shared_word_topics*np.array(corpus_lsi[input_ind])[:,1]) \\\n",
    "                                    + (shared_word_topics*np.array(corpus_lsi[candidate_ind])[:,1]), axis=1)\n",
    "\n",
    "    # Rank shared words by highest weighed word-topic loadings\n",
    "    ranking = np.argsort(-shared_lsi_word_loadings)\n",
    "    ranked_shared_word_ids = shared_word_ids[ranking]\n",
    "\n",
    "    tags = [dictionary[r] for r in ranked_shared_word_ids][:n_tags]\n",
    "    scores = shared_lsi_word_loadings[ranking][:n_tags]\n",
    "    return tags, scores\n",
    "\n",
    "def show_recommendations_with_tags(input_ind, internal_n_recs=50, show_n_recs=5,\n",
    "                                   n_input_tags=10, n_candidate_tags=5):\n",
    "    sims = lsi_vecs_normed[input_ind].dot(lsi_vecs_normed.T)\n",
    "    top_inds = np.argsort(-sims)[:internal_n_recs]\n",
    "\n",
    "    results = []\n",
    "    all_tags = []\n",
    "    for candidate_ind in top_inds:\n",
    "        tags, scores = extract_tags(input_ind, candidate_ind, n_tags=n_candidate_tags)\n",
    "        results.append([candidate_ind, tags, scores])\n",
    "        all_tags.extend(tags)\n",
    "\n",
    "    print(documents[input_ind])\n",
    "    print(Counter(all_tags).most_common(n_input_tags))\n",
    "    print('='*150)\n",
    "    print()\n",
    "\n",
    "    for data in results[:show_n_recs]:\n",
    "        print(documents[data[0]])\n",
    "        display(list(zip(data[1], data[2])))\n",
    "        print('-'*150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51457f16-22ee-48f1-a214-988220e72078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Straight-cut, linen-blend jacket in a patterned weave with a shawl collar, padded shoulders and long sleeves with decorative buttons at the cuffs. Buttons at the front and front pockets. Lined.\n",
      "[('buttons', 43), ('cut', 35), ('straight', 35), ('linen', 32), ('jacket', 31), ('decorative', 18), ('blend', 12), ('collar', 10), ('weave', 9), ('shoulders', 7)]\n",
      "======================================================================================================================================================\n",
      "\n",
      "Straight-cut, linen-blend jacket in a patterned weave with a shawl collar, padded shoulders and long sleeves with decorative buttons at the cuffs. Buttons at the front and front pockets. Lined.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('buttons', 0.6640270897830053),\n",
       " ('linen', 0.6474020570456075),\n",
       " ('cut', 0.48276344712755204),\n",
       " ('straight', 0.4279763355143735),\n",
       " ('decorative', 0.42295154709549243)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Straight-cut jacket in a patterned linen and viscose weave with notch lapels, buttons at the front, welt front pockets and decorative buttons at the cuffs. Partly lined.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('buttons', 0.6663840119373068),\n",
       " ('linen', 0.6460366893667935),\n",
       " ('cut', 0.4762145099332802),\n",
       " ('jacket', 0.4514144555624118),\n",
       " ('straight', 0.43481499143204294)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Straight-cut, double-breasted jacket in a patterned weave with notch lapels and covered buttons at the front. Long sleeves with decorative buttons at the cuffs and welt front pockets with a flap. Lined.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('buttons', 0.6663925547698731),\n",
       " ('cut', 0.48066311987661875),\n",
       " ('jacket', 0.4469697835887205),\n",
       " ('straight', 0.4211543145105651),\n",
       " ('decorative', 0.40672920496643855)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Straight-cut jacket in woven fabric with a shawl collar, thin shoulder pads, jetted front pockets and no buttons. Lined.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('buttons', 0.501594116934601),\n",
       " ('cut', 0.48387922628842),\n",
       " ('straight', 0.43169388781843715),\n",
       " ('jacket', 0.4023984568715535),\n",
       " ('collar', 0.2646230191469885)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Linen-blend jacket in a herringbone weave with notch lapels, a covered button at the front, welt front pockets with a flap, and decorative buttons at the cuffs. Lined.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('linen', 0.6370003612129868),\n",
       " ('buttons', 0.510355252164045),\n",
       " ('jacket', 0.421569619197373),\n",
       " ('decorative', 0.39685611634302975),\n",
       " ('blend', 0.3613195647872708)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TODO: Ability to re-rank by selecting tags\n",
    "show_recommendations_with_tags(10000, internal_n_recs=50, show_n_recs=5,\n",
    "                               n_input_tags=10, n_candidate_tags=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2e07f08-2f31-45a4-a74b-956155d3b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_topic_matrix_T_normed = lsi_topic_matrix.T/np.linalg.norm(lsi_topic_matrix.T, axis=1)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dbbb6fd2-5372-4475-b307-079692aa0461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['single', 'breasted', 'jacket', 'stretch', 'weave', 'containing', 'wool', 'narrow', 'notch', 'lapels', 'decorative', 'buttonhole', 'fastening', 'buttons', 'chest', 'pocket', 'flap', 'pockets', 'inner', 'pockets', 'button', 'decorative', 'buttons', 'cuffs', 'single', 'vent', 'lined', 'skinny', 'fit', 'slightly', 'shorter', 'style', 'shapes', 'chest', 'tapers', 'sharply', 'waist', 'combined', 'narrow', 'shoulders', 'sleeves', 'creates', 'completely', 'fitted', 'silhouette']\n",
      "narrower\n",
      "tuxedo\n",
      "linked\n",
      "special\n",
      "search\n"
     ]
    }
   ],
   "source": [
    "# TODO: Can give the user options of adjacent tags so that they can get new queries entirely?\n",
    "# They can remove tags from the input document and add in other tags, like swapping out pants for jeans, etc.\n",
    "# This results in a \"new\" input document\n",
    "\n",
    "tags = cleaned_documents[777]\n",
    "print(tags)\n",
    "bow = dictionary.doc2bow(tags)\n",
    "bow_vec = lsi_corpus2vec(lsi_model[tfidf[bow]])\n",
    "bow_vec_normed = bow_vec/np.linalg.norm(bow_vec)\n",
    "sims = bow_vec_normed.dot(lsi_topic_matrix_T_normed.T)\n",
    "top_inds = np.argsort(-sims)\n",
    "count = 0\n",
    "for t in top_inds:\n",
    "    tag = dictionary[t]\n",
    "    if tag not in tags:\n",
    "        print(tag)\n",
    "        count += 1\n",
    "    if count == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9701477-ca3a-42be-bca1-50eb8e22ef5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e425b80-35d2-464e-863c-648bceecbb76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fee26fa-33d4-4b84-9604-3773eea584b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a428a9-5565-46e9-8643-85597d3f963f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "380ea9af-20bf-4c74-aa4d-8bc137968845",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TagExtractor:\n",
    "    def __init__(self, \n",
    "                 word_count_min=2, \n",
    "                 word_length_min=2, \n",
    "                 num_lsi_topics=300):\n",
    "        self.word_count_min = word_count_min\n",
    "        self.word_length_min = word_length_min\n",
    "        self.num_lsi_topics = num_lsi_topics\n",
    "    \n",
    "    def fit(self, documents):\n",
    "        # Clean text\n",
    "        # TODO: TextCleaner needs a fit and transform method so that I can look up word counts for new documents\n",
    "        self.tc = TextCleaner(word_count_min=self.word_count_min, \n",
    "                              word_length_min=self.word_length_min)\n",
    "        cleaned_documents = self.tc.clean_documents(documents)\n",
    "            \n",
    "        # Create document lookup\n",
    "        self.problem_docs = []\n",
    "        self.doc2ind = {}\n",
    "        for n, (doc, cleaned_doc) in enumerate(zip(documents, cleaned_documents)):\n",
    "            if len(cleaned_doc)==0:\n",
    "                import pdb; pdb.set_trace()\n",
    "                self.problem_docs.append(doc)\n",
    "            self.doc2ind[doc] = n\n",
    "                \n",
    "        # Warn for empty documents\n",
    "        if len(self.problem_docs) > 0:\n",
    "            print(\"\"\"Warning: Some documents yield no clean tokens. These documents won't have tags. Check self.problem_docs for more detail.\"\"\")\n",
    "        \n",
    "        # Train TF-IDF\n",
    "        self.dictionary = corpora.Dictionary(cleaned_documents)\n",
    "        self.corpus = [self.dictionary.doc2bow(doc) for doc in cleaned_documents]\n",
    "        self.tfidf = models.TfidfModel(self.corpus)\n",
    "        self.corpus_tfidf = self.tfidf[self.corpus]\n",
    "\n",
    "        # Train LSI\n",
    "        self.lsi_model = models.LsiModel(self.corpus_tfidf, \n",
    "                                         id2word=self.dictionary, \n",
    "                                         num_topics=self.num_lsi_topics)\n",
    "        self.corpus_lsi = self.lsi_model[self.corpus_tfidf]\n",
    "        \n",
    "        # Save the topic matrix for tag extraction\n",
    "        self.lsi_topic_matrix = self.lsi_model.get_topics()\n",
    "        \n",
    "    def _transform(self, document):\n",
    "        doc_ind = self.doc2ind.get(document) \n",
    "        if doc_ind is None:\n",
    "            # TODO: TextCleaner needs a fit and transform method so that I can look up word counts for new documents\n",
    "            cleaned_documents = self.tc.clean_documents([document], display_progress=False)\n",
    "            corpus = self.dictionary.doc2bow(cleaned_documents[0])\n",
    "            corpus_tfidf = self.tfidf[corpus]\n",
    "            corpus_lsi = self.lsi_model[corpus_tfidf]\n",
    "        else:\n",
    "            corpus_tfidf = self.corpus_tfidf[doc_ind]\n",
    "            corpus_lsi = self.corpus_lsi[doc_ind]\n",
    "        return corpus_tfidf, corpus_lsi\n",
    "    \n",
    "    def extract_tags_and_rank(self, input_document, ranked_candidate_documents, \n",
    "                              n_input_tags, n_candidate_tags, selected_tags=[]):\n",
    "        tfidf_input, lsi_input = self._transform(input_document)\n",
    "        if (len(tfidf_input) == 0) | (len(lsi_input) == 0):\n",
    "            return [], [], []\n",
    "        \n",
    "        tag_scores = []\n",
    "        for candidate_document in ranked_candidate_documents:\n",
    "            tfidf_candidate, lsi_candidate = self._transform(candidate_document)\n",
    "            \n",
    "            if (len(tfidf_candidate) == 0) | (len(lsi_candidate) == 0):\n",
    "                tag_scores.append({})\n",
    "            else:\n",
    "\n",
    "                # Get shared words using the sparse TF-IDF corpus\n",
    "                shared_word_ids = np.array(list(set(np.array(tfidf_input)[:,0]) \\\n",
    "                                              & set(np.array(tfidf_candidate)[:,0]))).astype(int)\n",
    "\n",
    "                # Get word-topic vectors for those shared words\n",
    "                shared_word_topics = self.lsi_topic_matrix.T[shared_word_ids]\n",
    "\n",
    "                # Sum those word-topic vectors weighed by each document's topic loadings\n",
    "                shared_lsi_word_loadings = np.sum((shared_word_topics*np.array(lsi_input)[:,1]) \\\n",
    "                                                + (shared_word_topics*np.array(lsi_candidate)[:,1]), axis=1)\n",
    "\n",
    "                # Rank shared words by highest weighed word-topic loadings\n",
    "                ranking = np.argsort(shared_lsi_word_loadings)[::-1]\n",
    "                ranked_shared_word_ids = shared_word_ids[ranking]\n",
    "\n",
    "                tags = [self.dictionary[r] for r in ranked_shared_word_ids][:n_candidate_tags]\n",
    "                scores = shared_lsi_word_loadings[ranking][:n_candidate_tags].tolist()\n",
    "\n",
    "                tag_scores.append(dict(zip(tags, scores)))\n",
    "            \n",
    "        all_candidate_tags = list(itertools.chain(*[list(ts.keys()) for ts in tag_scores]))\n",
    "        input_tags = Counter(all_candidate_tags).most_common(n_input_tags)\n",
    "        \n",
    "        if len(selected_tags) > 0:\n",
    "            reranking_scores = []\n",
    "            for tag_dict in tag_scores:\n",
    "                document_score = sum(tag_dict.get(tag,0) for tag in selected_tags)\n",
    "                reranking_scores.append(document_score)\n",
    "            ranking = np.argsort(-np.array(reranking_scores)).tolist()\n",
    "        else:\n",
    "            ranking = list(range(len(ranked_candidate_documents)))\n",
    "            \n",
    "        return input_tags, tag_scores, ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "00add3b3-3cfc-4015-83cd-f25440bfcad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 43404/43404 [00:04<00:00, 9508.30it/s]\n"
     ]
    }
   ],
   "source": [
    "te = TagExtractor(word_count_min=1, word_length_min=2, num_lsi_topics=200)\n",
    "te.fit(df['detail_desc'].drop_duplicates().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "79e592f1-697d-4151-b781-893204351d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Jersey top with narrow shoulder straps.',\n",
       "       'Microfibre T-shirt bra with underwired, moulded, lightly padded cups that shape the bust and provide good support. Narrow adjustable shoulder straps and a narrow hook-and-eye fastening at the back. Without visible seams for greater comfort.',\n",
       "       'Semi shiny nylon stockings with a wide, reinforced trim at the top. Use with a suspender belt. 20 denier.',\n",
       "       'Tights with built-in support to lift the bottom. Black in 30 denier and light amber in 15 denier.',\n",
       "       'Semi shiny tights that shape the tummy, thighs and calves while also encouraging blood circulation in the legs. Elasticated waist.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['detail_desc'].drop_duplicates().values[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c5c22477-da3b-42e9-88b0-be6dd0fb5e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('narrow', 1), ('shoulder', 1), ('straps', 1), ('jersey', 1)],\n",
       " [{},\n",
       "  {},\n",
       "  {'narrow': 1.0847161183274086,\n",
       "   'shoulder': 1.0523107110568781,\n",
       "   'straps': 0.9339358005822074,\n",
       "   'jersey': 0.5775927072817127}],\n",
       " [0, 1, 2])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te.extract_tags_and_rank(input_document='Jersey top with narrow shoulder straps.', \n",
    "                         ranked_candidate_documents=[\n",
    "                             'Tights with built-in support to lift the bottom. Black in 30 denier and light amber in 15 denier.',\n",
    "                             'Semi shiny tights that shape the tummy, thighs and calves while also encouraging blood circulation in the legs. Elasticated waist.',\n",
    "                             'Jersey top with narrow shoulder straps.'\n",
    "                          ], \n",
    "                          n_input_tags=10, n_candidate_tags=5, \n",
    "                          selected_tags=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6304ca40-debd-4ea7-844a-67260717996c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('narrow', 1), ('shoulder', 1), ('straps', 1), ('jersey', 1)],\n",
       " [{},\n",
       "  {},\n",
       "  {'narrow': 1.0847161183274086,\n",
       "   'shoulder': 1.0523107110568781,\n",
       "   'straps': 0.9339358005822074,\n",
       "   'jersey': 0.5775927072817127}],\n",
       " [2, 0, 1])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te.extract_tags_and_rank(input_document='Jersey top with narrow shoulder straps.', \n",
    "                         ranked_candidate_documents=[\n",
    "                             'Tights with built-in support to lift the bottom. Black in 30 denier and light amber in 15 denier.',\n",
    "                             'Semi shiny tights that shape the tummy, thighs and calves while also encouraging blood circulation in the legs. Elasticated waist.',\n",
    "                             'Jersey top with narrow shoulder straps.'\n",
    "                          ], \n",
    "                          n_input_tags=10, n_candidate_tags=5, \n",
    "                          selected_tags=['narrow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a2bfd0-addc-4372-adad-8df469ee4a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
